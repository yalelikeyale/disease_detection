{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display \n",
    "\n",
    "### Training and test set\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, LinearRegression\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from mlens.visualization import corrmat\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./all/health-diagnostics-train.csv')\n",
    "test = pd.read_csv('./all/health-diagnostics-test.csv')\n",
    "\n",
    "df.replace('#NULL!',np.nan, inplace=True)\n",
    "df.iloc[:, 0:(len(df.columns)-1)] = df.select_dtypes(include='object').apply(pd.to_numeric)\n",
    "df.dropna(inplace=True)\n",
    "test.replace('#NULL!',np.nan, inplace=True)\n",
    "test = test.select_dtypes(include='object').apply(pd.to_numeric)\n",
    "imp = Imputer(strategy='most_frequent')\n",
    "imp.fit(test)\n",
    "F_test = imp.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target',axis=1)\n",
    "F_test = pd.DataFrame(F_test, columns=X.columns)\n",
    "NoFam_test = F_test.drop('fam-history',axis=1)\n",
    "NoFam_X = X.drop('fam-history',axis=1)\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "NoFam_X.reset_index(drop=True, inplace=True)\n",
    "y=df['target']\n",
    "y.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 111\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = X_train.index\n",
    "test_idx = X_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fam_Xtrain, Fam_Xtest = NoFam_X.iloc[train_idx], NoFam_X.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    lrc = LogisticRegression(C=10, class_weight='balanced', random_state=seed)\n",
    "    \n",
    "    sgd = SGDClassifier(loss='log', class_weight={0:0.01,1:0.99}, random_state=seed)\n",
    "    \n",
    "    rfc = RandomForestClassifier(\n",
    "        n_estimators=25,\n",
    "        max_depth=5,\n",
    "        min_impurity_decrease=0.02,\n",
    "        min_samples_leaf=0.003,\n",
    "        min_samples_split=0.01,\n",
    "        class_weight={0:0.01,1:0.99},\n",
    "        max_features='auto',\n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    noFam_rfc = RandomForestClassifier(n_estimators=110, \n",
    "                           max_depth=2, \n",
    "                           min_samples_leaf=0.001, \n",
    "                           min_samples_split=0.03, \n",
    "                           class_weight={0: 0.01, 1: 0.99}, \n",
    "                           random_state=seed)\n",
    "    \n",
    "    nb = GaussianNB()\n",
    "    \n",
    "    models = {\n",
    "        'lrc':lrc,\n",
    "        'sgd':sgd,\n",
    "        'rfc':rfc,\n",
    "        'nb':nb,\n",
    "        'noFam':noFam_rfc\n",
    "    }\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_base_learners(base_learners, inp, fam_inp, out, verbose=True):\n",
    "    \"\"\"Train all base learners in the library.\"\"\"\n",
    "    if verbose: print(\"Fitting models.\")\n",
    "    for i, (name, m) in enumerate(base_learners.items()):\n",
    "        if verbose: \n",
    "            print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        if name == 'noFam':\n",
    "            m.fit(fam_inp, out)\n",
    "        else:\n",
    "            m.fit(inp, out)\n",
    "        if verbose: print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_base_learners(pred_base_learners, inp, fam_inp, verbose=True):\n",
    "    \"\"\"Generate a prediction matrix.\"\"\"\n",
    "    P = np.zeros((inp.shape[0], len(pred_base_learners)))\n",
    "\n",
    "    if verbose: print(\"Generating base learner predictions.\")\n",
    "    for i, (name, m) in enumerate(pred_base_learners.items()):\n",
    "        if verbose: \n",
    "            print(\"%s...\" % name, end=\" \", flush=False)\n",
    "        if name == 'noFam':\n",
    "            p = m.predict_proba(fam_inp)\n",
    "        else:\n",
    "            p = m.predict_proba(inp)\n",
    "        P[:, i] = p[:, 1]\n",
    "        if verbose: print(\"done\")\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(base_learners, meta_learner, inp, fam_inp, verbose=True):\n",
    "    \"\"\"Generate predictions from the ensemble.\"\"\"\n",
    "    P_pred = predict_base_learners(base_learners, inp, fam_inp, verbose=verbose)\n",
    "    return P_pred, meta_learner.predict(P_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking(base_learners, meta_learner, X_stack, Fam_Xstack, y_stack, generator):\n",
    "    print(\"Fitting final base learners...\", end=\"\")\n",
    "    train_base_learners(base_learners, X_stack, Fam_Xstack, y_stack, verbose=False)\n",
    "    print(\"done\")\n",
    "    kf = KFold(n_splits=10, random_state=seed)\n",
    "    cv_preds, cv_y = [], []\n",
    "    for i, (train_idx, test_idx) in enumerate(kf.split(X_stack)):\n",
    "        fold_xtrain, fold_ytrain = X_stack.iloc[train_idx, :], y_stack.iloc[train_idx]\n",
    "        fam_xtrain, fam_ytrain = Fam_Xstack.iloc[train_idx, :], y_stack.iloc[train_idx]\n",
    "        fold_xtest, fold_ytest = X_stack.iloc[test_idx, :], y_stack.iloc[test_idx]\n",
    "        fam_xtest, fam_ytest = Fam_Xstack.iloc[test_idx, :], y_stack.iloc[test_idx]\n",
    "        \n",
    "        # Inner loop: step 4 and 5\n",
    "        fold_base_learners = {name: clone(model) for name, model in base_learners.items()}\n",
    "        train_base_learners(fold_base_learners, fold_xtrain, fam_xtrain, fold_ytrain, verbose=False)\n",
    "        fold_P_base = predict_base_learners(fold_base_learners, fold_xtest, fam_xtest, verbose=False)\n",
    "\n",
    "        cv_preds.append(fold_P_base)\n",
    "        cv_y.append(fold_ytest)\n",
    "        print(\"Fold %i done\" % (i + 1))\n",
    "\n",
    "    np.vstack(cv_preds)\n",
    "    X_meta = np.vstack(cv_preds)\n",
    "    y_meta = np.hstack(cv_y)\n",
    "    meta_learner.fit(X_meta, y_meta)\n",
    "    return base_learners, meta_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_rfc = RandomForestClassifier(\n",
    "    n_estimators=25, \n",
    "    max_depth=4, \n",
    "    max_features=3, \n",
    "    min_impurity_decrease=0.02, \n",
    "    min_samples_leaf=0.003,\n",
    "    min_samples_split=0.01,\n",
    "    class_weight={0:0.01, 1:0.99})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting final base learners..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 6 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 7 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 8 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 9 done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 10 done\n"
     ]
    }
   ],
   "source": [
    "weak_learners, meta_learner = stacking(get_models(), meta_rfc, X_train, Fam_Xtrain, y_train, KFold(n_splits=10, random_state=seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating base learner predictions.\n",
      "lrc... done\n",
      "sgd... done\n",
      "rfc... done\n",
      "nb... done\n",
      "noFam... done\n"
     ]
    }
   ],
   "source": [
    "P, y_pred = ensemble_predict(weak_learners, meta_learner, X_test, Fam_Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_out = pd.DataFrame(P, columns=['lrc','sgd','rfc','nb','noFam'])\n",
    "actuals = pd.Series(y_test).reset_index(drop=True)\n",
    "preds = pd.Series(y_pred).reset_index(drop=True)\n",
    "test = pd.concat([model_out,preds,actuals],axis=1)\n",
    "test.columns = ['lrc','sgd','rfc','nb','noFam','pred','actual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.where(model_out['rfc']>0.6,1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = test[(test['pred']==1)&(test['actual']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = test[(test['pred']==0)&(test['actual']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lrc</th>\n",
       "      <th>sgd</th>\n",
       "      <th>rfc</th>\n",
       "      <th>nb</th>\n",
       "      <th>noFam</th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "      <th>noFam_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>0.620718</td>\n",
       "      <td>0.273747</td>\n",
       "      <td>0.116641</td>\n",
       "      <td>0.119808</td>\n",
       "      <td>0.188115</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>0.291240</td>\n",
       "      <td>0.124522</td>\n",
       "      <td>0.116641</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.148271</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6064</th>\n",
       "      <td>0.438295</td>\n",
       "      <td>0.158655</td>\n",
       "      <td>0.116641</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.135719</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6689</th>\n",
       "      <td>0.243004</td>\n",
       "      <td>0.123404</td>\n",
       "      <td>0.116641</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.134157</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lrc       sgd       rfc        nb     noFam  pred  actual  \\\n",
       "2591  0.620718  0.273747  0.116641  0.119808  0.188115     0       1   \n",
       "2868  0.291240  0.124522  0.116641  0.000020  0.148271     0       1   \n",
       "6064  0.438295  0.158655  0.116641  0.000033  0.135719     0       1   \n",
       "6689  0.243004  0.123404  0.116641  0.000042  0.134157     0       1   \n",
       "\n",
       "      noFam_pred  \n",
       "2591           1  \n",
       "2868           0  \n",
       "6064           0  \n",
       "6689           0  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = test[(test['pred']==1)&(test['actual']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lrc</th>\n",
       "      <th>sgd</th>\n",
       "      <th>rfc</th>\n",
       "      <th>nb</th>\n",
       "      <th>noFam</th>\n",
       "      <th>pred</th>\n",
       "      <th>actual</th>\n",
       "      <th>noFam_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2306</th>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.992868</td>\n",
       "      <td>0.599202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.199182</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>0.980694</td>\n",
       "      <td>0.740276</td>\n",
       "      <td>0.599202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133700</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3603</th>\n",
       "      <td>0.995736</td>\n",
       "      <td>0.920390</td>\n",
       "      <td>0.599202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.223515</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3876</th>\n",
       "      <td>0.990908</td>\n",
       "      <td>0.859528</td>\n",
       "      <td>0.599202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.164697</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4484</th>\n",
       "      <td>0.992774</td>\n",
       "      <td>0.844202</td>\n",
       "      <td>0.599202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.170946</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>0.992209</td>\n",
       "      <td>0.853002</td>\n",
       "      <td>0.599202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.171424</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5846</th>\n",
       "      <td>0.984684</td>\n",
       "      <td>0.767661</td>\n",
       "      <td>0.599202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142253</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6033</th>\n",
       "      <td>0.993529</td>\n",
       "      <td>0.835964</td>\n",
       "      <td>0.599202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.173020</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6673</th>\n",
       "      <td>0.998167</td>\n",
       "      <td>0.889185</td>\n",
       "      <td>0.596727</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.395790</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           lrc       sgd       rfc   nb     noFam  pred  actual  noFam_pred\n",
       "2306  0.999980  0.992868  0.599202  1.0  0.199182     1       1           1\n",
       "3093  0.980694  0.740276  0.599202  1.0  0.133700     1       1           0\n",
       "3603  0.995736  0.920390  0.599202  1.0  0.223515     1       1           1\n",
       "3876  0.990908  0.859528  0.599202  1.0  0.164697     1       1           1\n",
       "4484  0.992774  0.844202  0.599202  1.0  0.170946     1       1           1\n",
       "4771  0.992209  0.853002  0.599202  1.0  0.171424     1       1           1\n",
       "5846  0.984684  0.767661  0.599202  1.0  0.142253     1       1           0\n",
       "6033  0.993529  0.835964  0.599202  1.0  0.173020     1       1           1\n",
       "6673  0.998167  0.889185  0.596727  1.0  0.395790     1       1           1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundaries = np.linspace(0.01, 0.5, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_boundary = 0 \n",
    "best_score = 0\n",
    "for boundary in boundaries:\n",
    "    score = roc_auc_score(y_test, np.where(test['noFam']>boundary,1,0))\n",
    "    if score > best_score:\n",
    "        best_boundary = boundary\n",
    "        best_score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.673476931178353"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15291666666666667"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['noFam_pred'] = np.where(test['noFam']>0.15,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
